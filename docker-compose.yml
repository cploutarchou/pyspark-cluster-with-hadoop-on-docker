version: "3"

services:

  jupyterlab:
    image: cploutarchou/jupyterlab:latest
    container_name: jupyterlab
    ports:
      - "8888:8888"
    volumes:
      - ./data:/opt/app/data
    entrypoint: sh -c 'jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --notebook-dir=/opt/app/data --allow-root'

  namenode:
    image: cploutarchou/hadoop-base:namenode
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=dev
    env_file:
      - ./conf/hadoop/hadoop.env
    networks:
      hadoop:
        ipv4_address: 10.5.0.5

  datanode:
    image: cploutarchou/hadoop-base:datanode
    container_name: datanode
    restart: always
    ports:
      - 9864:9864
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "10.5.0.5:9870"
    env_file:
      - ./conf/hadoop/hadoop.env
    networks:
      hadoop:
        ipv4_address: 10.5.0.2

  resourcemanager:
    image: cploutarchou/hadoop-base:resource-manager
    container_name: resourcemanager
    restart: always
    ports:
      - 8088:8088
    environment:
      SERVICE_PRECONDITION: "10.5.0.5:9000 10.5.0.5:9870 10.5.0.2:9864"
    env_file:
      - ./conf/hadoop/hadoop.env
    networks:
      hadoop:
        ipv4_address: 10.5.0.3

  nodemanager1:
    image: cploutarchou/hadoop-base:hadoop-nodemanager
    container_name: nodemanager
    restart: always
    ports:
      - 8042:8042
    environment:
      SERVICE_PRECONDITION: "10.5.0.5:9000 10.5.0.5:9870 10.5.0.2:9864 10.5.0.3:8088"
    env_file:
      - ./conf/hadoop/hadoop.env
    networks:
      hadoop:
        ipv4_address: 10.5.0.4

  historyserver:
    image: cploutarchou/hadoop-base:history-server
    container_name: historyserver
    restart: always
    ports:
      - 8188:8188
    environment:
      SERVICE_PRECONDITION: "10.5.0.5:9000 10.5.0.5:9870 10.5.0.2:9864 10.5.0.3:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./conf/hadoop/hadoop.env
    networks:
      hadoop:
        ipv4_address: 10.5.0.6

  spark-master:
    image: cploutarchou/spark-base:spark-master-image
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - shared-workspace:/opt/workspace
    networks:
      hadoop:
        ipv4_address: 10.5.0.7

  spark-worker-1:
    image: cploutarchou/spark-base:spark-worker-image
    container_name: spark-worker-1
    environment:
      - SERVICE_PRECONDITION: "10.5.0.7:8080 10.5.0.7:7077"
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1024m
    ports:
      - 8081:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      hadoop:
        ipv4_address: 10.5.0.8

  spark-worker-2:
    image: cploutarchou/spark-base:spark-worker-image
    container_name: spark-worker-2
    environment:
      - SERVICE_PRECONDITION: "10.5.0.7:8080 10.5.0.7:7077"
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1024m
    ports:
      - 8082:8081
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      hadoop:
        ipv4_address: 10.5.0.9


volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
networks:
  hadoop:
    driver: bridge
    ipam:
      config:
        - subnet: 10.5.0.1/16
